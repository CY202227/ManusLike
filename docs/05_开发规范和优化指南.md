# æ•°å­—å‘˜å·¥å¼€å‘è§„èŒƒå’Œä¼˜åŒ–æŒ‡å—

## ğŸ“‹ ç›®å½•

1. [å¼€å‘ç¯å¢ƒæ­å»º](#å¼€å‘ç¯å¢ƒæ­å»º)
2. [ä»£ç è§„èŒƒ](#ä»£ç è§„èŒƒ)
3. [å¼€å‘æµç¨‹](#å¼€å‘æµç¨‹)
4. [æµ‹è¯•è§„èŒƒ](#æµ‹è¯•è§„èŒƒ)
5. [æ€§èƒ½ä¼˜åŒ–](#æ€§èƒ½ä¼˜åŒ–)
6. [å®‰å…¨è§„èŒƒ](#å®‰å…¨è§„èŒƒ)
7. [æ¶æ„ä¼˜åŒ–](#æ¶æ„ä¼˜åŒ–)
8. [éƒ¨ç½²ä¼˜åŒ–](#éƒ¨ç½²ä¼˜åŒ–)

## ğŸ› ï¸ å¼€å‘ç¯å¢ƒæ­å»º

### 1. å¼€å‘å·¥å…·æ¨è

**IDE/ç¼–è¾‘å™¨**:
- PyCharm Professional (æ¨è)
- Visual Studio Code + Pythonæ‰©å±•
- Vim + Pythonæ’ä»¶

**å¿…å¤‡å·¥å…·**:
```bash
# ä»£ç æ ¼å¼åŒ–
pip install black isort

# ä»£ç æ£€æŸ¥  
pip install flake8 pylint mypy

# æµ‹è¯•å·¥å…·
pip install pytest pytest-asyncio pytest-cov

# æ–‡æ¡£ç”Ÿæˆ
pip install sphinx sphinx-rtd-theme

# å¼€å‘è¾…åŠ©
pip install pre-commit ipython
```

### 2. å¼€å‘ç¯å¢ƒé…ç½®

#### Git Hooksé…ç½®

```bash
# å®‰è£…pre-commit
pip install pre-commit

# åˆ›å»º.pre-commit-config.yaml
cat > .pre-commit-config.yaml << EOF
repos:
  - repo: https://github.com/psf/black
    rev: 22.3.0
    hooks:
      - id: black
        language_version: python3
        
  - repo: https://github.com/pycqa/isort
    rev: 5.10.1
    hooks:
      - id: isort
        
  - repo: https://github.com/pycqa/flake8
    rev: 4.0.1
    hooks:
      - id: flake8
        args: [--max-line-length=88, --ignore=E203,W503]
        
  - repo: https://github.com/pre-commit/mirrors-mypy
    rev: v0.950
    hooks:
      - id: mypy
        additional_dependencies: [types-requests]
EOF

# å®‰è£…hooks
pre-commit install
```

#### IDEé…ç½®

**PyCharmé…ç½®**:
```python
# File -> Settings -> Editor -> Code Style -> Python
# Line length: 88
# Use tabs: False
# Tab size: 4
# Indent: 4

# File -> Settings -> Tools -> External Tools
# æ·»åŠ Blackæ ¼å¼åŒ–å·¥å…·
# æ·»åŠ isortå¯¼å…¥æ’åºå·¥å…·
```

**VSCodeé…ç½®** (`.vscode/settings.json`):
```json
{
    "python.formatting.provider": "black",
    "python.formatting.blackArgs": ["--line-length", "88"],
    "python.sortImports.args": ["--profile", "black"],
    "python.linting.enabled": true,
    "python.linting.flake8Enabled": true,
    "python.linting.mypyEnabled": true,
    "editor.formatOnSave": true,
    "editor.codeActionsOnSave": {
        "source.organizeImports": true
    }
}
```

### 3. è°ƒè¯•é…ç½®

#### æ—¥å¿—è°ƒè¯•é…ç½®

```python
# debug_config.py
import logging
import sys

def setup_debug_logging():
    """è®¾ç½®è°ƒè¯•æ—¥å¿—"""
    logging.basicConfig(
        level=logging.DEBUG,
        format='%(asctime)s - %(name)s - %(levelname)s - %(filename)s:%(lineno)d - %(message)s',
        handlers=[
            logging.StreamHandler(sys.stdout),
            logging.FileHandler('debug.log')
        ]
    )
    
    # è®¾ç½®ç‰¹å®šæ¨¡å—çš„æ—¥å¿—çº§åˆ«
    logging.getLogger('asyncio').setLevel(logging.WARNING)
    logging.getLogger('urllib3').setLevel(logging.WARNING)
```

#### æ–­ç‚¹è°ƒè¯•ç¤ºä¾‹

```python
# ä½¿ç”¨pdbè¿›è¡Œè°ƒè¯•
import pdb

async def debug_task_execution():
    """è°ƒè¯•ä»»åŠ¡æ‰§è¡Œè¿‡ç¨‹"""
    pdb.set_trace()  # è®¾ç½®æ–­ç‚¹
    
    task_plan = await task_planner.analyze_task(user_input)
    # åœ¨è¿™é‡Œå¯ä»¥æ£€æŸ¥task_plançš„å†…å®¹
    
    execution_result = await task_executor.execute_plan(task_plan)
    # æ£€æŸ¥æ‰§è¡Œç»“æœ
```

## ğŸ“ ä»£ç è§„èŒƒ

### 1. Pythonç¼–ç è§„èŒƒ

#### åŸºæœ¬è§„èŒƒ

```python
# éµå¾ªPEP 8è§„èŒƒ
# è¡Œé•¿åº¦é™åˆ¶ä¸º88å­—ç¬¦ï¼ˆBlacké»˜è®¤ï¼‰
# ä½¿ç”¨4ä¸ªç©ºæ ¼ç¼©è¿›ï¼Œä¸ä½¿ç”¨Tab

# å¯¼å…¥é¡ºåº
import asyncio  # æ ‡å‡†åº“
import logging
from datetime import datetime
from typing import Dict, List, Optional  # æ ‡å‡†åº“ç±»å‹

import aiohttp  # ç¬¬ä¸‰æ–¹åº“
import pydantic
from openai import OpenAI

from core.models import TaskPlan  # æœ¬åœ°æ¨¡å—
from tools.tool_manager import ToolManager
```

#### å‘½åè§„èŒƒ

```python
# ç±»åä½¿ç”¨PascalCase
class TaskPlanner:
    pass

class ExecutionEventEmitter:
    pass

# å‡½æ•°å’Œå˜é‡ä½¿ç”¨snake_case
def analyze_task():
    pass

def execute_plan():
    pass

user_input = "hello"
task_plan = TaskPlan()

# å¸¸é‡ä½¿ç”¨UPPER_CASE
MAX_RETRY_COUNT = 3
DEFAULT_TIMEOUT = 30

# ç§æœ‰æ–¹æ³•å’Œå±æ€§ä½¿ç”¨ä¸‹åˆ’çº¿å‰ç¼€
def _internal_method():
    pass

self._private_attribute = None
```

#### ç±»å‹æ³¨è§£

```python
from typing import Dict, List, Optional, Union, Any
from datetime import datetime

class TaskExecutor:
    """ä»»åŠ¡æ‰§è¡Œå™¨ç±»"""
    
    def __init__(self, 
                 tool_manager: ToolManager, 
                 file_manager: Optional[FileManager] = None) -> None:
        self.tool_manager = tool_manager
        self.file_manager = file_manager
        self.execution_queue: List[TaskPlan] = []
    
    async def execute_plan(self, 
                          task_plan: TaskPlan, 
                          user_id: str = "default") -> ExecutionResult:
        """
        æ‰§è¡Œä»»åŠ¡è®¡åˆ’
        
        Args:
            task_plan: è¦æ‰§è¡Œçš„ä»»åŠ¡è®¡åˆ’
            user_id: ç”¨æˆ·ID
            
        Returns:
            ExecutionResult: æ‰§è¡Œç»“æœ
            
        Raises:
            ExecutionError: æ‰§è¡Œå¤±è´¥æ—¶æŠ›å‡º
        """
        # å®ç°ä»£ç ...
        pass
```

#### æ–‡æ¡£å­—ç¬¦ä¸²è§„èŒƒ

```python
def analyze_task_complexity(user_input: str, plan: Plan) -> Dict[str, str]:
    """
    åˆ†æä»»åŠ¡å¤æ‚åº¦å’Œç±»å‹
    
    è¿™ä¸ªå‡½æ•°æ ¹æ®ç”¨æˆ·è¾“å…¥å’Œç”Ÿæˆçš„è®¡åˆ’æ¥è¯„ä¼°ä»»åŠ¡çš„å¤æ‚ç¨‹åº¦ï¼Œ
    å¹¶ç¡®å®šä»»åŠ¡çš„å…·ä½“ç±»å‹ã€‚
    
    Args:
        user_input (str): ç”¨æˆ·åŸå§‹è¾“å…¥æ–‡æœ¬
        plan (Plan): ç”Ÿæˆçš„æ‰§è¡Œè®¡åˆ’å¯¹è±¡
        
    Returns:
        Dict[str, str]: åŒ…å«ä»¥ä¸‹é”®çš„å­—å…¸:
            - complexity_level: å¤æ‚åº¦ç­‰çº§ (simple/medium/complex)
            - task_type: ä»»åŠ¡ç±»å‹ (å¦‚: ä»£ç å¼€å‘ã€æ•°æ®åˆ†æç­‰)
            
    Example:
        >>> user_input = "ç”Ÿæˆä¸€ä¸ªPythonç¨‹åº"
        >>> plan = Plan(steps=[...])
        >>> result = analyze_task_complexity(user_input, plan)
        >>> print(result)
        {'complexity_level': 'medium', 'task_type': 'ä»£ç å¼€å‘'}
        
    Note:
        å¤æ‚åº¦åˆ¤æ–­æ ‡å‡†:
        - simple: 1ä¸ªæ­¥éª¤
        - medium: 2-3ä¸ªæ­¥éª¤  
        - complex: 4ä¸ªä»¥ä¸Šæ­¥éª¤
    """
    # å®ç°ä»£ç ...
```

### 2. å¼‚æ­¥ç¼–ç¨‹è§„èŒƒ

#### å¼‚æ­¥å‡½æ•°å®šä¹‰

```python
# æ­£ç¡®çš„å¼‚æ­¥å‡½æ•°å®šä¹‰
async def process_task(task_plan: TaskPlan) -> ExecutionResult:
    """å¤„ç†ä»»åŠ¡ - å¼‚æ­¥ç‰ˆæœ¬"""
    # ä½¿ç”¨awaitè°ƒç”¨å¼‚æ­¥å‡½æ•°
    result = await tool_manager.call_tool(tool_name, args)
    return result

# åŒæ­¥å‡½æ•°å¤„ç†å¼‚æ­¥è°ƒç”¨
def process_task_sync(task_plan: TaskPlan) -> ExecutionResult:
    """å¤„ç†ä»»åŠ¡ - åŒæ­¥ç‰ˆæœ¬"""
    # åœ¨åŒæ­¥å‡½æ•°ä¸­è¿è¡Œå¼‚æ­¥ä»£ç 
    loop = asyncio.get_event_loop()
    return loop.run_until_complete(process_task(task_plan))
```

#### å¼‚å¸¸å¤„ç†

```python
async def safe_tool_call(tool_name: str, args: Dict[str, Any]) -> Any:
    """å®‰å…¨çš„å·¥å…·è°ƒç”¨ï¼ŒåŒ…å«é‡è¯•æœºåˆ¶"""
    max_retries = 3
    last_exception = None
    
    for attempt in range(max_retries):
        try:
            result = await tool_manager.call_tool(tool_name, args)
            return result
            
        except ToolNotAvailableError as e:
            logger.error(f"å·¥å…·ä¸å¯ç”¨: {tool_name}")
            raise  # ä¸é‡è¯•ï¼Œç›´æ¥æŠ›å‡º
            
        except TimeoutError as e:
            last_exception = e
            wait_time = 2 ** attempt  # æŒ‡æ•°é€€é¿
            logger.warning(f"å·¥å…·è°ƒç”¨è¶…æ—¶ï¼Œ{wait_time}ç§’åé‡è¯• (å°è¯• {attempt + 1}/{max_retries})")
            await asyncio.sleep(wait_time)
            
        except Exception as e:
            last_exception = e
            logger.error(f"å·¥å…·è°ƒç”¨å¤±è´¥: {e}")
            if attempt < max_retries - 1:
                await asyncio.sleep(1)
            
    # æ‰€æœ‰é‡è¯•éƒ½å¤±è´¥
    raise ToolCallError(f"å·¥å…·è°ƒç”¨æœ€ç»ˆå¤±è´¥: {last_exception}")
```

### 3. é”™è¯¯å¤„ç†è§„èŒƒ

#### è‡ªå®šä¹‰å¼‚å¸¸

```python
# exceptions.py
class DigitalEmployeeError(Exception):
    """æ•°å­—å‘˜å·¥ç³»ç»ŸåŸºç¡€å¼‚å¸¸"""
    pass

class TaskPlanningError(DigitalEmployeeError):
    """ä»»åŠ¡è§„åˆ’å¼‚å¸¸"""
    def __init__(self, message: str, user_input: str = None):
        super().__init__(message)
        self.user_input = user_input

class ExecutionError(DigitalEmployeeError):
    """ä»»åŠ¡æ‰§è¡Œå¼‚å¸¸"""
    def __init__(self, message: str, task_id: str = None, step_id: str = None):
        super().__init__(message)
        self.task_id = task_id
        self.step_id = step_id

class ToolCallError(DigitalEmployeeError):
    """å·¥å…·è°ƒç”¨å¼‚å¸¸"""
    def __init__(self, message: str, tool_name: str = None, args: Dict = None):
        super().__init__(message)
        self.tool_name = tool_name
        self.args = args
```

#### å¼‚å¸¸å¤„ç†æœ€ä½³å®è·µ

```python
async def execute_step_with_error_handling(step: Step) -> Any:
    """å¸¦å®Œå–„é”™è¯¯å¤„ç†çš„æ­¥éª¤æ‰§è¡Œ"""
    try:
        # å‚æ•°éªŒè¯
        if not step.function_name:
            raise ValueError("æ­¥éª¤ç¼ºå°‘function_name")
        
        # å·¥å…·å¯ç”¨æ€§æ£€æŸ¥
        if not tool_manager.is_tool_available(step.function_name):
            raise ToolNotAvailableError(f"å·¥å…·ä¸å¯ç”¨: {step.function_name}")
        
        # æ‰§è¡Œå·¥å…·è°ƒç”¨
        result = await tool_manager.call_tool(step.function_name, step.args)
        
        # ç»“æœéªŒè¯
        if result is None:
            logger.warning(f"å·¥å…· {step.function_name} è¿”å›ç©ºç»“æœ")
        
        return result
        
    except ToolNotAvailableError:
        # è®°å½•å¹¶é‡æ–°æŠ›å‡ºï¼Œä¸å¤„ç†
        logger.error(f"å·¥å…·ä¸å¯ç”¨: {step.function_name}")
        raise
        
    except ValidationError as e:
        # å‚æ•°éªŒè¯é”™è¯¯
        error_msg = f"æ­¥éª¤å‚æ•°éªŒè¯å¤±è´¥: {e}"
        logger.error(error_msg)
        raise ExecutionError(error_msg, step_id=step.step_id)
        
    except TimeoutError as e:
        # è¶…æ—¶é”™è¯¯
        error_msg = f"æ­¥éª¤æ‰§è¡Œè¶…æ—¶: {step.step_description}"
        logger.error(error_msg)
        raise ExecutionError(error_msg, step_id=step.step_id)
        
    except Exception as e:
        # æœªé¢„æœŸçš„é”™è¯¯
        error_msg = f"æ­¥éª¤æ‰§è¡Œå‘ç”ŸæœªçŸ¥é”™è¯¯: {str(e)}"
        logger.exception(error_msg)  # è®°å½•å®Œæ•´å †æ ˆ
        raise ExecutionError(error_msg, step_id=step.step_id)
```

## ğŸ”„ å¼€å‘æµç¨‹

### 1. Gitå·¥ä½œæµ

#### åˆ†æ”¯ç®¡ç†

```bash
# ä¸»åˆ†æ”¯
main          # ç”Ÿäº§ç‰ˆæœ¬
develop       # å¼€å‘ç‰ˆæœ¬

# åŠŸèƒ½åˆ†æ”¯
feature/task-planner-improvement
feature/web-ui-enhancement
feature/new-tool-integration

# ä¿®å¤åˆ†æ”¯
bugfix/execution-error-handling
hotfix/critical-security-fix

# å‘å¸ƒåˆ†æ”¯
release/v1.2.0
```

#### æäº¤è§„èŒƒ

```bash
# æäº¤æ¶ˆæ¯æ ¼å¼
<type>(<scope>): <subject>

<body>

<footer>

# ç±»å‹è¯´æ˜
feat:     æ–°åŠŸèƒ½
fix:      bugä¿®å¤
docs:     æ–‡æ¡£æ›´æ–°
style:    ä»£ç æ ¼å¼åŒ–
refactor: é‡æ„
test:     æµ‹è¯•ç›¸å…³
chore:    æ„å»ºå·¥å…·ã€ä¾èµ–æ›´æ–°

# ç¤ºä¾‹
feat(task-planner): æ·»åŠ ä»»åŠ¡æ”¹è¿›æ£€æµ‹åŠŸèƒ½

å®ç°äº†å¯¹ç”¨æˆ·è¾“å…¥çš„æ”¹è¿›è¯·æ±‚æ£€æµ‹ï¼Œèƒ½å¤Ÿè¯†åˆ«å¯¹å·²å®Œæˆä»»åŠ¡çš„
ä¿®æ”¹è¦æ±‚ï¼Œå¹¶ç”Ÿæˆç›¸åº”çš„æ”¹è¿›è®¡åˆ’ã€‚

- æ–°å¢ _detect_task_improvement æ–¹æ³•
- æ–°å¢ _handle_task_improvement æ–¹æ³•
- æ›´æ–° analyze_task ä¸»æµç¨‹

Closes #123
```

### 2. å¼€å‘æµç¨‹

#### åŠŸèƒ½å¼€å‘æµç¨‹

```bash
# 1. åˆ›å»ºåŠŸèƒ½åˆ†æ”¯
git checkout develop
git pull origin develop
git checkout -b feature/new-feature

# 2. å¼€å‘å’Œæµ‹è¯•
# ç¼–å†™ä»£ç ...
python -m pytest tests/
python -m flake8 .
python -m black .

# 3. æäº¤ä»£ç 
git add -A
git commit -m "feat: æ·»åŠ æ–°åŠŸèƒ½"

# 4. æ¨é€å¹¶åˆ›å»ºPR
git push origin feature/new-feature
# åœ¨GitHub/GitLabåˆ›å»ºPull Request

# 5. ä»£ç å®¡æŸ¥é€šè¿‡ååˆå¹¶
git checkout develop
git pull origin develop
git branch -d feature/new-feature
```

#### å‘å¸ƒæµç¨‹

```bash
# 1. åˆ›å»ºå‘å¸ƒåˆ†æ”¯
git checkout develop
git pull origin develop
git checkout -b release/v1.2.0

# 2. æ›´æ–°ç‰ˆæœ¬å·å’ŒCHANGELOG
echo "1.2.0" > VERSION
# æ›´æ–° CHANGELOG.md

# 3. æœ€ç»ˆæµ‹è¯•
python -m pytest tests/
python scripts/integration_test.py

# 4. åˆå¹¶åˆ°main
git checkout main
git merge release/v1.2.0
git tag v1.2.0
git push origin main --tags

# 5. åˆå¹¶å›develop
git checkout develop
git merge release/v1.2.0
git push origin develop

# 6. æ¸…ç†
git branch -d release/v1.2.0
```

### 3. ä»£ç å®¡æŸ¥è§„èŒƒ

#### å®¡æŸ¥æ¸…å•

```markdown
## åŠŸèƒ½æ€§æ£€æŸ¥
- [ ] ä»£ç å®ç°ç¬¦åˆéœ€æ±‚
- [ ] è¾¹ç•Œæ¡ä»¶å¤„ç†æ­£ç¡®
- [ ] é”™è¯¯å¤„ç†å®Œæ•´
- [ ] å¼‚æ­¥ä»£ç æ­£ç¡®ä½¿ç”¨await

## ä»£ç è´¨é‡æ£€æŸ¥
- [ ] ä»£ç é£æ ¼ç¬¦åˆé¡¹ç›®è§„èŒƒ
- [ ] å‘½åæ¸…æ™°æ˜“æ‡‚
- [ ] å‡½æ•°èŒè´£å•ä¸€
- [ ] æ³¨é‡Šå’Œæ–‡æ¡£å®Œæ•´

## æ€§èƒ½æ£€æŸ¥
- [ ] æ— æ€§èƒ½ç“¶é¢ˆ
- [ ] å†…å­˜ä½¿ç”¨åˆç†
- [ ] æ•°æ®åº“æŸ¥è¯¢ä¼˜åŒ–
- [ ] å¼‚æ­¥æ“ä½œé«˜æ•ˆ

## å®‰å…¨æ£€æŸ¥
- [ ] è¾“å…¥éªŒè¯å®Œæ•´
- [ ] æ— SQLæ³¨å…¥é£é™©
- [ ] æ•æ„Ÿä¿¡æ¯æœªç¡¬ç¼–ç 
- [ ] æƒé™æ£€æŸ¥æ­£ç¡®

## æµ‹è¯•æ£€æŸ¥
- [ ] å•å…ƒæµ‹è¯•è¦†ç›–ç‡ > 80%
- [ ] é›†æˆæµ‹è¯•é€šè¿‡
- [ ] è¾¹ç•Œæ¡ä»¶æµ‹è¯•
- [ ] å¼‚å¸¸æƒ…å†µæµ‹è¯•
```

## ğŸ§ª æµ‹è¯•è§„èŒƒ

### 1. å•å…ƒæµ‹è¯•

#### æµ‹è¯•ç»“æ„

```python
# tests/test_task_planner.py
import pytest
from unittest.mock import Mock, AsyncMock, patch
from core.task_planner import TaskPlanner, TaskClarityAnalyzer
from core.models import TaskPlan, TaskClarityScore

class TestTaskPlanner:
    """ä»»åŠ¡è§„åˆ’å™¨æµ‹è¯•ç±»"""
    
    @pytest.fixture
    async def task_planner(self):
        """åˆ›å»ºæµ‹è¯•ç”¨çš„ä»»åŠ¡è§„åˆ’å™¨"""
        mock_llm_client = Mock()
        mock_tool_manager = Mock()
        mock_tool_manager.get_tools_for_planning.return_value = []
        
        planner = TaskPlanner(
            llm_client=mock_llm_client,
            tool_manager=mock_tool_manager
        )
        return planner
    
    @pytest.mark.asyncio
    async def test_analyze_simple_task(self, task_planner):
        """æµ‹è¯•ç®€å•ä»»åŠ¡åˆ†æ"""
        # å‡†å¤‡æµ‹è¯•æ•°æ®
        user_input = "ç”Ÿæˆä¸€ä¸ªPython hello worldç¨‹åº"
        
        # Mock LLMå“åº”
        mock_response = Mock()
        mock_response.choices[0].message.parsed = TaskClarityScore(
            clarity_score=9,
            has_clear_action=True,
            has_sufficient_params=True,
            is_simple_task=True,
            needs_clarification=False
        )
        
        with patch.object(task_planner.llm_client.beta.chat.completions, 'parse', 
                         return_value=mock_response):
            # æ‰§è¡Œæµ‹è¯•
            result = await task_planner.analyze_task(user_input)
            
            # éªŒè¯ç»“æœ
            assert isinstance(result, TaskPlan)
            assert result.user_input == user_input
            assert result.task_type != ""
            assert len(result.plan.steps) > 0
    
    @pytest.mark.asyncio
    async def test_analyze_unclear_task_requires_clarification(self, task_planner):
        """æµ‹è¯•ä¸æ˜ç¡®ä»»åŠ¡éœ€è¦æ¾„æ¸…"""
        user_input = "å¸®æˆ‘ç”Ÿæˆä¸€ä¸ªç¨‹åº"
        
        # Mockè¿”å›éœ€è¦æ¾„æ¸…çš„å“åº”
        mock_clarity_response = Mock()
        mock_clarity_response.choices[0].message.parsed = TaskClarityScore(
            clarity_score=3,
            has_clear_action=False,
            has_sufficient_params=False,
            is_simple_task=False,
            needs_clarification=True
        )
        
        mock_clarification_response = {
            "needs_clarification": True,
            "questions": ["æ‚¨å¸Œæœ›ç”Ÿæˆä»€ä¹ˆç±»å‹çš„ç¨‹åºï¼Ÿ", "ç¨‹åºéœ€è¦å®ç°ä»€ä¹ˆåŠŸèƒ½ï¼Ÿ"]
        }
        
        with patch.object(task_planner.clarity_analyzer, 'analyze_clarity',
                         return_value=mock_clarity_response.choices[0].message.parsed):
            with patch.object(task_planner, '_analyze_requirements',
                             return_value=mock_clarification_response):
                
                result = await task_planner.analyze_task(user_input)
                
                assert result.requires_clarification == True
                assert len(result.clarification_questions) > 0
                assert "ç¨‹åº" in result.clarification_questions[0]
```

#### æµ‹è¯•è¦†ç›–ç‡

```bash
# è¿è¡Œæµ‹è¯•å¹¶ç”Ÿæˆè¦†ç›–ç‡æŠ¥å‘Š
python -m pytest tests/ --cov=core --cov-report=html --cov-report=term

# æ£€æŸ¥è¦†ç›–ç‡é˜ˆå€¼
python -m pytest tests/ --cov=core --cov-fail-under=80
```

### 2. é›†æˆæµ‹è¯•

```python
# tests/test_integration.py
import pytest
import asyncio
from pathlib import Path
from core import TaskPlanner, TaskExecutor, FileManager
from tools.tool_manager import ToolManager
from communication.mcp_client import MultiMCPClient

class TestSystemIntegration:
    """ç³»ç»Ÿé›†æˆæµ‹è¯•"""
    
    @pytest.fixture(scope="session")
    async def system_components(self):
        """è®¾ç½®å®Œæ•´ç³»ç»Ÿç»„ä»¶"""
        # åˆå§‹åŒ–æ‰€æœ‰ç»„ä»¶
        mcp_client = MultiMCPClient()
        tool_manager = ToolManager(mcp_client)
        await tool_manager.load_all_tools()
        
        file_manager = FileManager()
        task_planner = TaskPlanner(
            llm_client=get_test_llm_client(),
            tool_manager=tool_manager
        )
        task_executor = TaskExecutor(
            tool_manager=tool_manager,
            file_manager=file_manager
        )
        
        return {
            'task_planner': task_planner,
            'task_executor': task_executor,
            'file_manager': file_manager,
            'tool_manager': tool_manager
        }
    
    @pytest.mark.asyncio
    async def test_complete_task_workflow(self, system_components):
        """æµ‹è¯•å®Œæ•´ä»»åŠ¡å·¥ä½œæµ"""
        planner = system_components['task_planner']
        executor = system_components['task_executor']
        
        # 1. ä»»åŠ¡åˆ†æ
        user_input = "ç”Ÿæˆä¸€ä¸ªç®€å•çš„Pythonè®¡ç®—å™¨"
        task_plan = await planner.analyze_task(user_input)
        
        assert task_plan is not None
        assert not task_plan.requires_clarification
        assert len(task_plan.plan.steps) > 0
        
        # 2. ä»»åŠ¡æ‰§è¡Œ
        execution_result = await executor.execute_plan(task_plan)
        
        assert execution_result.success == True
        assert len(execution_result.files_generated) > 0
        
        # 3. éªŒè¯ç”Ÿæˆçš„æ–‡ä»¶
        for file_path in execution_result.files_generated:
            assert Path(file_path).exists()
            assert Path(file_path).stat().st_size > 0
```

### 3. æµ‹è¯•æ•°æ®ç®¡ç†

```python
# tests/fixtures.py
import pytest
from pathlib import Path
import tempfile
import shutil

@pytest.fixture
def temp_test_dir():
    """åˆ›å»ºä¸´æ—¶æµ‹è¯•ç›®å½•"""
    temp_dir = tempfile.mkdtemp()
    yield Path(temp_dir)
    shutil.rmtree(temp_dir)

@pytest.fixture
def sample_task_plan():
    """åˆ›å»ºç¤ºä¾‹ä»»åŠ¡è®¡åˆ’"""
    from core.models import TaskPlan, Plan, Step
    
    return TaskPlan(
        user_input="æµ‹è¯•ä»»åŠ¡",
        task_type="æµ‹è¯•",
        complexity_level="simple",
        plan=Plan(steps=[
            Step(
                step_description="æµ‹è¯•æ­¥éª¤",
                function_name="test_tool",
                args={"param": "value"},
                is_final=True
            )
        ])
    )

# æµ‹è¯•é…ç½®æ–‡ä»¶
# pytest.ini
[tool:pytest]
testpaths = tests
python_files = test_*.py
python_classes = Test*
python_functions = test_*
addopts = 
    --strict-markers
    --strict-config
    --cov=core
    --cov=tools
    --cov=communication
    --cov-report=term-missing
    --cov-report=html:htmlcov
    --cov-fail-under=80

markers =
    slow: marks tests as slow
    integration: marks tests as integration tests
    unit: marks tests as unit tests
```

## âš¡ æ€§èƒ½ä¼˜åŒ–

### 1. å¼‚æ­¥å¹¶å‘ä¼˜åŒ–

#### å¹¶å‘æ‰§è¡Œä¼˜åŒ–

```python
import asyncio
from concurrent.futures import ThreadPoolExecutor
from typing import List, Any

class OptimizedTaskExecutor:
    """ä¼˜åŒ–çš„ä»»åŠ¡æ‰§è¡Œå™¨"""
    
    def __init__(self, max_concurrent_tools: int = 5):
        self.max_concurrent_tools = max_concurrent_tools
        self.semaphore = asyncio.Semaphore(max_concurrent_tools)
        self.thread_pool = ThreadPoolExecutor(max_workers=4)
    
    async def execute_tools_concurrently(self, tool_calls: List[Dict]) -> List[Any]:
        """å¹¶å‘æ‰§è¡Œå¤šä¸ªå·¥å…·è°ƒç”¨"""
        async def execute_single_tool(tool_call):
            async with self.semaphore:  # é™åˆ¶å¹¶å‘æ•°
                return await self.tool_manager.call_tool(
                    tool_call['name'], 
                    tool_call['args']
                )
        
        # åˆ›å»ºå¹¶å‘ä»»åŠ¡
        tasks = [execute_single_tool(call) for call in tool_calls]
        
        # å¹¶å‘æ‰§è¡Œ
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        return results
    
    async def execute_cpu_intensive_task(self, func, *args, **kwargs):
        """åœ¨çº¿ç¨‹æ± ä¸­æ‰§è¡ŒCPUå¯†é›†å‹ä»»åŠ¡"""
        loop = asyncio.get_event_loop()
        return await loop.run_in_executor(self.thread_pool, func, *args, **kwargs)
```

#### ç¼“å­˜ä¼˜åŒ–

```python
import asyncio
from functools import lru_cache, wraps
from typing import Dict, Any
import hashlib
import json
import time

class AsyncLRUCache:
    """å¼‚æ­¥LRUç¼“å­˜"""
    
    def __init__(self, maxsize: int = 128, ttl: int = 3600):
        self.maxsize = maxsize
        self.ttl = ttl
        self.cache: Dict[str, Dict] = {}
    
    def _get_cache_key(self, func_name: str, args: tuple, kwargs: dict) -> str:
        """ç”Ÿæˆç¼“å­˜é”®"""
        key_data = {
            'func': func_name,
            'args': args,
            'kwargs': kwargs
        }
        key_str = json.dumps(key_data, sort_keys=True, default=str)
        return hashlib.md5(key_str.encode()).hexdigest()
    
    def _is_expired(self, cache_entry: Dict) -> bool:
        """æ£€æŸ¥ç¼“å­˜æ˜¯å¦è¿‡æœŸ"""
        return time.time() - cache_entry['timestamp'] > self.ttl
    
    def cached(self, func):
        """ç¼“å­˜è£…é¥°å™¨"""
        @wraps(func)
        async def wrapper(*args, **kwargs):
            cache_key = self._get_cache_key(func.__name__, args, kwargs)
            
            # æ£€æŸ¥ç¼“å­˜
            if cache_key in self.cache:
                cache_entry = self.cache[cache_key]
                if not self._is_expired(cache_entry):
                    return cache_entry['result']
                else:
                    del self.cache[cache_key]
            
            # æ‰§è¡Œå‡½æ•°
            result = await func(*args, **kwargs)
            
            # å­˜å‚¨åˆ°ç¼“å­˜
            if len(self.cache) >= self.maxsize:
                # åˆ é™¤æœ€æ—§çš„æ¡ç›®
                oldest_key = min(self.cache.keys(), 
                               key=lambda k: self.cache[k]['timestamp'])
                del self.cache[oldest_key]
            
            self.cache[cache_key] = {
                'result': result,
                'timestamp': time.time()
            }
            
            return result
        return wrapper

# ä½¿ç”¨ç¤ºä¾‹
cache = AsyncLRUCache(maxsize=100, ttl=1800)

class CachedTaskPlanner(TaskPlanner):
    @cache.cached
    async def analyze_task(self, user_input: str) -> TaskPlan:
        """å¸¦ç¼“å­˜çš„ä»»åŠ¡åˆ†æ"""
        return await super().analyze_task(user_input)
```

### 2. å†…å­˜ä¼˜åŒ–

#### å†…å­˜ç›‘æ§

```python
import psutil
import gc
from typing import Optional
import logging

class MemoryMonitor:
    """å†…å­˜ç›‘æ§å™¨"""
    
    def __init__(self, max_memory_mb: int = 1024):
        self.max_memory_mb = max_memory_mb
        self.logger = logging.getLogger(__name__)
    
    def get_memory_usage(self) -> Dict[str, float]:
        """è·å–å†…å­˜ä½¿ç”¨æƒ…å†µ"""
        process = psutil.Process()
        memory_info = process.memory_info()
        
        return {
            'rss_mb': memory_info.rss / 1024 / 1024,
            'vms_mb': memory_info.vms / 1024 / 1024,
            'percent': process.memory_percent()
        }
    
    def check_memory_limit(self) -> bool:
        """æ£€æŸ¥å†…å­˜é™åˆ¶"""
        memory_usage = self.get_memory_usage()
        
        if memory_usage['rss_mb'] > self.max_memory_mb:
            self.logger.warning(f"å†…å­˜ä½¿ç”¨è¶…é™: {memory_usage['rss_mb']:.1f}MB")
            return False
        
        return True
    
    def force_garbage_collection(self):
        """å¼ºåˆ¶åƒåœ¾å›æ”¶"""
        before = self.get_memory_usage()
        
        gc.collect()
        
        after = self.get_memory_usage()
        freed = before['rss_mb'] - after['rss_mb']
        
        self.logger.info(f"åƒåœ¾å›æ”¶é‡Šæ”¾å†…å­˜: {freed:.1f}MB")

# å†…å­˜ç®¡ç†è£…é¥°å™¨
def memory_managed(max_memory_mb: int = 1024):
    """å†…å­˜ç®¡ç†è£…é¥°å™¨"""
    monitor = MemoryMonitor(max_memory_mb)
    
    def decorator(func):
        @wraps(func)
        async def wrapper(*args, **kwargs):
            # æ‰§è¡Œå‰æ£€æŸ¥å†…å­˜
            if not monitor.check_memory_limit():
                monitor.force_garbage_collection()
            
            try:
                result = await func(*args, **kwargs)
                return result
            finally:
                # æ‰§è¡Œåæ¸…ç†
                if not monitor.check_memory_limit():
                    monitor.force_garbage_collection()
        
        return wrapper
    return decorator
```

#### å¤§æ–‡ä»¶å¤„ç†ä¼˜åŒ–

```python
import aiofiles
from typing import AsyncIterator

class OptimizedFileManager(FileManager):
    """ä¼˜åŒ–çš„æ–‡ä»¶ç®¡ç†å™¨"""
    
    async def read_large_file_chunks(self, 
                                   file_path: str, 
                                   chunk_size: int = 8192) -> AsyncIterator[bytes]:
        """åˆ†å—è¯»å–å¤§æ–‡ä»¶"""
        async with aiofiles.open(file_path, 'rb') as f:
            while True:
                chunk = await f.read(chunk_size)
                if not chunk:
                    break
                yield chunk
    
    async def process_large_file(self, file_path: str) -> None:
        """å¤„ç†å¤§æ–‡ä»¶è€Œä¸åŠ è½½åˆ°å†…å­˜"""
        total_size = 0
        hash_obj = hashlib.sha256()
        
        async for chunk in self.read_large_file_chunks(file_path):
            total_size += len(chunk)
            hash_obj.update(chunk)
            
            # å®šæœŸæ£€æŸ¥å†…å­˜ä½¿ç”¨
            if total_size % (1024 * 1024) == 0:  # æ¯1MBæ£€æŸ¥ä¸€æ¬¡
                gc.collect()
        
        file_hash = hash_obj.hexdigest()
        logger.info(f"æ–‡ä»¶å¤„ç†å®Œæˆ: {file_path}, å¤§å°: {total_size}, å“ˆå¸Œ: {file_hash}")
```

### 3. æ•°æ®åº“ä¼˜åŒ–

```python
import asyncpg
from typing import List, Dict, Any
import json

class OptimizedDatabase:
    """ä¼˜åŒ–çš„æ•°æ®åº“æ“ä½œç±»"""
    
    def __init__(self, connection_pool):
        self.pool = connection_pool
    
    async def batch_insert_tasks(self, tasks: List[Dict[str, Any]]) -> None:
        """æ‰¹é‡æ’å…¥ä»»åŠ¡"""
        async with self.pool.acquire() as conn:
            # ä½¿ç”¨COPYè¿›è¡Œæ‰¹é‡æ’å…¥
            await conn.copy_records_to_table(
                'tasks',
                records=[(
                    task['task_id'],
                    task['user_input'],
                    task['task_type'],
                    json.dumps(task['plan']),
                    task['status']
                ) for task in tasks]
            )
    
    async def get_tasks_with_pagination(self, 
                                      user_id: str, 
                                      page: int = 1, 
                                      page_size: int = 20) -> List[Dict]:
        """åˆ†é¡µè·å–ä»»åŠ¡"""
        offset = (page - 1) * page_size
        
        async with self.pool.acquire() as conn:
            # ä½¿ç”¨ç´¢å¼•ä¼˜åŒ–æŸ¥è¯¢
            rows = await conn.fetch("""
                SELECT task_id, user_input, task_type, status, created_at
                FROM tasks 
                WHERE user_id = $1 
                ORDER BY created_at DESC 
                LIMIT $2 OFFSET $3
            """, user_id, page_size, offset)
            
            return [dict(row) for row in rows]
```

## ğŸ”’ å®‰å…¨è§„èŒƒ

### 1. è¾“å…¥éªŒè¯

```python
from pydantic import BaseModel, validator, Field
import re
from typing import Optional

class SecureTaskInput(BaseModel):
    """å®‰å…¨çš„ä»»åŠ¡è¾“å…¥æ¨¡å‹"""
    
    user_input: str = Field(..., min_length=1, max_length=10000)
    user_id: str = Field(..., regex=r'^[a-zA-Z0-9_-]+$')
    
    @validator('user_input')
    def validate_user_input(cls, v):
        """éªŒè¯ç”¨æˆ·è¾“å…¥"""
        # æ£€æŸ¥æ¶æ„å†…å®¹
        malicious_patterns = [
            r'<script.*?</script>',  # XSS
            r'javascript:',           # JavaScriptåè®®
            r'on\w+\s*=',            # äº‹ä»¶å¤„ç†å™¨
            r'eval\s*\(',            # evalå‡½æ•°
            r'exec\s*\(',            # execå‡½æ•°
        ]
        
        for pattern in malicious_patterns:
            if re.search(pattern, v, re.IGNORECASE):
                raise ValueError(f"è¾“å…¥åŒ…å«ä¸å®‰å…¨å†…å®¹")
        
        return v
    
    @validator('user_id')
    def validate_user_id(cls, v):
        """éªŒè¯ç”¨æˆ·ID"""
        if len(v) < 3 or len(v) > 50:
            raise ValueError("ç”¨æˆ·IDé•¿åº¦å¿…é¡»åœ¨3-50å­—ç¬¦ä¹‹é—´")
        return v

# ä½¿ç”¨ç¤ºä¾‹
def validate_input(user_input: str, user_id: str) -> SecureTaskInput:
    """éªŒè¯è¾“å…¥æ•°æ®"""
    try:
        return SecureTaskInput(user_input=user_input, user_id=user_id)
    except ValidationError as e:
        logger.error(f"è¾“å…¥éªŒè¯å¤±è´¥: {e}")
        raise
```

### 2. æƒé™æ§åˆ¶

```python
from functools import wraps
from typing import Set, Dict
import jwt
from datetime import datetime, timedelta

class PermissionManager:
    """æƒé™ç®¡ç†å™¨"""
    
    def __init__(self, secret_key: str):
        self.secret_key = secret_key
        self.user_permissions: Dict[str, Set[str]] = {}
    
    def generate_token(self, user_id: str, permissions: Set[str]) -> str:
        """ç”Ÿæˆè®¿é—®ä»¤ç‰Œ"""
        payload = {
            'user_id': user_id,
            'permissions': list(permissions),
            'exp': datetime.utcnow() + timedelta(hours=24),
            'iat': datetime.utcnow()
        }
        return jwt.encode(payload, self.secret_key, algorithm='HS256')
    
    def verify_token(self, token: str) -> Dict[str, Any]:
        """éªŒè¯è®¿é—®ä»¤ç‰Œ"""
        try:
            payload = jwt.decode(token, self.secret_key, algorithms=['HS256'])
            return payload
        except jwt.ExpiredSignatureError:
            raise PermissionError("ä»¤ç‰Œå·²è¿‡æœŸ")
        except jwt.InvalidTokenError:
            raise PermissionError("æ— æ•ˆä»¤ç‰Œ")
    
    def check_permission(self, user_id: str, required_permission: str) -> bool:
        """æ£€æŸ¥ç”¨æˆ·æƒé™"""
        user_perms = self.user_permissions.get(user_id, set())
        return required_permission in user_perms or 'admin' in user_perms

def require_permission(permission: str):
    """æƒé™æ£€æŸ¥è£…é¥°å™¨"""
    def decorator(func):
        @wraps(func)
        async def wrapper(*args, **kwargs):
            # ä»è¯·æ±‚ä¸­è·å–ç”¨æˆ·ä¿¡æ¯
            user_id = kwargs.get('user_id')
            if not user_id:
                raise PermissionError("ç¼ºå°‘ç”¨æˆ·ID")
            
            # æ£€æŸ¥æƒé™
            if not permission_manager.check_permission(user_id, permission):
                raise PermissionError(f"ç”¨æˆ· {user_id} ç¼ºå°‘æƒé™: {permission}")
            
            return await func(*args, **kwargs)
        return wrapper
    return decorator

# ä½¿ç”¨ç¤ºä¾‹
@require_permission('execute_task')
async def execute_task_with_permission(task_plan: TaskPlan, user_id: str):
    """éœ€è¦æƒé™çš„ä»»åŠ¡æ‰§è¡Œ"""
    return await task_executor.execute_plan(task_plan, user_id)
```

### 3. æ•æ„Ÿä¿¡æ¯ä¿æŠ¤

```python
import os
from cryptography.fernet import Fernet
from typing import Optional
import base64

class SecretManager:
    """æ•æ„Ÿä¿¡æ¯ç®¡ç†å™¨"""
    
    def __init__(self, key: Optional[bytes] = None):
        if key is None:
            # ä»ç¯å¢ƒå˜é‡è¯»å–å¯†é’¥
            key_str = os.getenv('ENCRYPTION_KEY')
            if key_str:
                self.key = base64.urlsafe_b64decode(key_str)
            else:
                # ç”Ÿæˆæ–°å¯†é’¥
                self.key = Fernet.generate_key()
        else:
            self.key = key
        
        self.cipher = Fernet(self.key)
    
    def encrypt(self, data: str) -> str:
        """åŠ å¯†æ•æ„Ÿæ•°æ®"""
        encrypted = self.cipher.encrypt(data.encode())
        return base64.urlsafe_b64encode(encrypted).decode()
    
    def decrypt(self, encrypted_data: str) -> str:
        """è§£å¯†æ•æ„Ÿæ•°æ®"""
        encrypted_bytes = base64.urlsafe_b64decode(encrypted_data.encode())
        decrypted = self.cipher.decrypt(encrypted_bytes)
        return decrypted.decode()

# é…ç½®ç®¡ç†
class SecureConfig:
    """å®‰å…¨é…ç½®ç®¡ç†"""
    
    def __init__(self):
        self.secret_manager = SecretManager()
    
    def get_api_key(self, service: str) -> str:
        """è·å–APIå¯†é’¥"""
        encrypted_key = os.getenv(f'{service.upper()}_API_KEY_ENCRYPTED')
        if encrypted_key:
            return self.secret_manager.decrypt(encrypted_key)
        
        # å¦‚æœæ²¡æœ‰åŠ å¯†ç‰ˆæœ¬ï¼Œæ£€æŸ¥ç¯å¢ƒå˜é‡
        return os.getenv(f'{service.upper()}_API_KEY', '')
    
    def set_api_key(self, service: str, api_key: str) -> None:
        """è®¾ç½®APIå¯†é’¥"""
        encrypted_key = self.secret_manager.encrypt(api_key)
        os.environ[f'{service.upper()}_API_KEY_ENCRYPTED'] = encrypted_key

# ä½¿ç”¨ç¤ºä¾‹
config = SecureConfig()
openai_api_key = config.get_api_key('openai')
```

### 4. æ—¥å¿—å®‰å…¨

```python
import logging
import re
from typing import Any, Dict

class SecureFormatter(logging.Formatter):
    """å®‰å…¨æ—¥å¿—æ ¼å¼åŒ–å™¨"""
    
    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
        
        # æ•æ„Ÿä¿¡æ¯æ¨¡å¼
        self.sensitive_patterns = [
            (r'api[_-]?key["\']?\s*[:=]\s*["\']?([a-zA-Z0-9\-_]+)', r'api_key=***'),
            (r'password["\']?\s*[:=]\s*["\']?([^"\'\s]+)', r'password=***'),
            (r'token["\']?\s*[:=]\s*["\']?([a-zA-Z0-9\-_\.]+)', r'token=***'),
            (r'Bearer\s+([a-zA-Z0-9\-_\.]+)', r'Bearer ***'),
        ]
    
    def format(self, record: logging.LogRecord) -> str:
        """æ ¼å¼åŒ–æ—¥å¿—è®°å½•ï¼Œéšè—æ•æ„Ÿä¿¡æ¯"""
        # è·å–åŸå§‹æ¶ˆæ¯
        message = super().format(record)
        
        # æ›¿æ¢æ•æ„Ÿä¿¡æ¯
        for pattern, replacement in self.sensitive_patterns:
            message = re.sub(pattern, replacement, message, flags=re.IGNORECASE)
        
        return message

# é…ç½®å®‰å…¨æ—¥å¿—
def setup_secure_logging():
    """è®¾ç½®å®‰å…¨æ—¥å¿—é…ç½®"""
    logger = logging.getLogger()
    handler = logging.StreamHandler()
    handler.setFormatter(SecureFormatter(
        '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
    ))
    logger.addHandler(handler)
    logger.setLevel(logging.INFO)
```

é€šè¿‡éµå¾ªè¿™äº›å¼€å‘è§„èŒƒå’Œä¼˜åŒ–æŒ‡å—ï¼Œå¯ä»¥ç¡®ä¿æ•°å­—å‘˜å·¥ç³»ç»Ÿçš„ä»£ç è´¨é‡ã€æ€§èƒ½å’Œå®‰å…¨æ€§è¾¾åˆ°ä¼ä¸šçº§æ ‡å‡†ã€‚ 
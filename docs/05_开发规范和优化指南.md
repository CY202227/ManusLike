# 数字员工开发规范和优化指南

## 📋 目录

1. [开发环境搭建](#开发环境搭建)
2. [代码规范](#代码规范)
3. [开发流程](#开发流程)
4. [测试规范](#测试规范)
5. [性能优化](#性能优化)
6. [安全规范](#安全规范)
7. [架构优化](#架构优化)
8. [部署优化](#部署优化)

## 🛠️ 开发环境搭建

### 1. 开发工具推荐

**IDE/编辑器**:
- PyCharm Professional (推荐)
- Visual Studio Code + Python扩展
- Vim + Python插件

**必备工具**:
```bash
# 代码格式化
pip install black isort

# 代码检查  
pip install flake8 pylint mypy

# 测试工具
pip install pytest pytest-asyncio pytest-cov

# 文档生成
pip install sphinx sphinx-rtd-theme

# 开发辅助
pip install pre-commit ipython
```

### 2. 开发环境配置

#### Git Hooks配置

```bash
# 安装pre-commit
pip install pre-commit

# 创建.pre-commit-config.yaml
cat > .pre-commit-config.yaml << EOF
repos:
  - repo: https://github.com/psf/black
    rev: 22.3.0
    hooks:
      - id: black
        language_version: python3
        
  - repo: https://github.com/pycqa/isort
    rev: 5.10.1
    hooks:
      - id: isort
        
  - repo: https://github.com/pycqa/flake8
    rev: 4.0.1
    hooks:
      - id: flake8
        args: [--max-line-length=88, --ignore=E203,W503]
        
  - repo: https://github.com/pre-commit/mirrors-mypy
    rev: v0.950
    hooks:
      - id: mypy
        additional_dependencies: [types-requests]
EOF

# 安装hooks
pre-commit install
```

#### IDE配置

**PyCharm配置**:
```python
# File -> Settings -> Editor -> Code Style -> Python
# Line length: 88
# Use tabs: False
# Tab size: 4
# Indent: 4

# File -> Settings -> Tools -> External Tools
# 添加Black格式化工具
# 添加isort导入排序工具
```

**VSCode配置** (`.vscode/settings.json`):
```json
{
    "python.formatting.provider": "black",
    "python.formatting.blackArgs": ["--line-length", "88"],
    "python.sortImports.args": ["--profile", "black"],
    "python.linting.enabled": true,
    "python.linting.flake8Enabled": true,
    "python.linting.mypyEnabled": true,
    "editor.formatOnSave": true,
    "editor.codeActionsOnSave": {
        "source.organizeImports": true
    }
}
```

### 3. 调试配置

#### 日志调试配置

```python
# debug_config.py
import logging
import sys

def setup_debug_logging():
    """设置调试日志"""
    logging.basicConfig(
        level=logging.DEBUG,
        format='%(asctime)s - %(name)s - %(levelname)s - %(filename)s:%(lineno)d - %(message)s',
        handlers=[
            logging.StreamHandler(sys.stdout),
            logging.FileHandler('debug.log')
        ]
    )
    
    # 设置特定模块的日志级别
    logging.getLogger('asyncio').setLevel(logging.WARNING)
    logging.getLogger('urllib3').setLevel(logging.WARNING)
```

#### 断点调试示例

```python
# 使用pdb进行调试
import pdb

async def debug_task_execution():
    """调试任务执行过程"""
    pdb.set_trace()  # 设置断点
    
    task_plan = await task_planner.analyze_task(user_input)
    # 在这里可以检查task_plan的内容
    
    execution_result = await task_executor.execute_plan(task_plan)
    # 检查执行结果
```

## 📝 代码规范

### 1. Python编码规范

#### 基本规范

```python
# 遵循PEP 8规范
# 行长度限制为88字符（Black默认）
# 使用4个空格缩进，不使用Tab

# 导入顺序
import asyncio  # 标准库
import logging
from datetime import datetime
from typing import Dict, List, Optional  # 标准库类型

import aiohttp  # 第三方库
import pydantic
from openai import OpenAI

from core.models import TaskPlan  # 本地模块
from tools.tool_manager import ToolManager
```

#### 命名规范

```python
# 类名使用PascalCase
class TaskPlanner:
    pass

class ExecutionEventEmitter:
    pass

# 函数和变量使用snake_case
def analyze_task():
    pass

def execute_plan():
    pass

user_input = "hello"
task_plan = TaskPlan()

# 常量使用UPPER_CASE
MAX_RETRY_COUNT = 3
DEFAULT_TIMEOUT = 30

# 私有方法和属性使用下划线前缀
def _internal_method():
    pass

self._private_attribute = None
```

#### 类型注解

```python
from typing import Dict, List, Optional, Union, Any
from datetime import datetime

class TaskExecutor:
    """任务执行器类"""
    
    def __init__(self, 
                 tool_manager: ToolManager, 
                 file_manager: Optional[FileManager] = None) -> None:
        self.tool_manager = tool_manager
        self.file_manager = file_manager
        self.execution_queue: List[TaskPlan] = []
    
    async def execute_plan(self, 
                          task_plan: TaskPlan, 
                          user_id: str = "default") -> ExecutionResult:
        """
        执行任务计划
        
        Args:
            task_plan: 要执行的任务计划
            user_id: 用户ID
            
        Returns:
            ExecutionResult: 执行结果
            
        Raises:
            ExecutionError: 执行失败时抛出
        """
        # 实现代码...
        pass
```

#### 文档字符串规范

```python
def analyze_task_complexity(user_input: str, plan: Plan) -> Dict[str, str]:
    """
    分析任务复杂度和类型
    
    这个函数根据用户输入和生成的计划来评估任务的复杂程度，
    并确定任务的具体类型。
    
    Args:
        user_input (str): 用户原始输入文本
        plan (Plan): 生成的执行计划对象
        
    Returns:
        Dict[str, str]: 包含以下键的字典:
            - complexity_level: 复杂度等级 (simple/medium/complex)
            - task_type: 任务类型 (如: 代码开发、数据分析等)
            
    Example:
        >>> user_input = "生成一个Python程序"
        >>> plan = Plan(steps=[...])
        >>> result = analyze_task_complexity(user_input, plan)
        >>> print(result)
        {'complexity_level': 'medium', 'task_type': '代码开发'}
        
    Note:
        复杂度判断标准:
        - simple: 1个步骤
        - medium: 2-3个步骤  
        - complex: 4个以上步骤
    """
    # 实现代码...
```

### 2. 异步编程规范

#### 异步函数定义

```python
# 正确的异步函数定义
async def process_task(task_plan: TaskPlan) -> ExecutionResult:
    """处理任务 - 异步版本"""
    # 使用await调用异步函数
    result = await tool_manager.call_tool(tool_name, args)
    return result

# 同步函数处理异步调用
def process_task_sync(task_plan: TaskPlan) -> ExecutionResult:
    """处理任务 - 同步版本"""
    # 在同步函数中运行异步代码
    loop = asyncio.get_event_loop()
    return loop.run_until_complete(process_task(task_plan))
```

#### 异常处理

```python
async def safe_tool_call(tool_name: str, args: Dict[str, Any]) -> Any:
    """安全的工具调用，包含重试机制"""
    max_retries = 3
    last_exception = None
    
    for attempt in range(max_retries):
        try:
            result = await tool_manager.call_tool(tool_name, args)
            return result
            
        except ToolNotAvailableError as e:
            logger.error(f"工具不可用: {tool_name}")
            raise  # 不重试，直接抛出
            
        except TimeoutError as e:
            last_exception = e
            wait_time = 2 ** attempt  # 指数退避
            logger.warning(f"工具调用超时，{wait_time}秒后重试 (尝试 {attempt + 1}/{max_retries})")
            await asyncio.sleep(wait_time)
            
        except Exception as e:
            last_exception = e
            logger.error(f"工具调用失败: {e}")
            if attempt < max_retries - 1:
                await asyncio.sleep(1)
            
    # 所有重试都失败
    raise ToolCallError(f"工具调用最终失败: {last_exception}")
```

### 3. 错误处理规范

#### 自定义异常

```python
# exceptions.py
class DigitalEmployeeError(Exception):
    """数字员工系统基础异常"""
    pass

class TaskPlanningError(DigitalEmployeeError):
    """任务规划异常"""
    def __init__(self, message: str, user_input: str = None):
        super().__init__(message)
        self.user_input = user_input

class ExecutionError(DigitalEmployeeError):
    """任务执行异常"""
    def __init__(self, message: str, task_id: str = None, step_id: str = None):
        super().__init__(message)
        self.task_id = task_id
        self.step_id = step_id

class ToolCallError(DigitalEmployeeError):
    """工具调用异常"""
    def __init__(self, message: str, tool_name: str = None, args: Dict = None):
        super().__init__(message)
        self.tool_name = tool_name
        self.args = args
```

#### 异常处理最佳实践

```python
async def execute_step_with_error_handling(step: Step) -> Any:
    """带完善错误处理的步骤执行"""
    try:
        # 参数验证
        if not step.function_name:
            raise ValueError("步骤缺少function_name")
        
        # 工具可用性检查
        if not tool_manager.is_tool_available(step.function_name):
            raise ToolNotAvailableError(f"工具不可用: {step.function_name}")
        
        # 执行工具调用
        result = await tool_manager.call_tool(step.function_name, step.args)
        
        # 结果验证
        if result is None:
            logger.warning(f"工具 {step.function_name} 返回空结果")
        
        return result
        
    except ToolNotAvailableError:
        # 记录并重新抛出，不处理
        logger.error(f"工具不可用: {step.function_name}")
        raise
        
    except ValidationError as e:
        # 参数验证错误
        error_msg = f"步骤参数验证失败: {e}"
        logger.error(error_msg)
        raise ExecutionError(error_msg, step_id=step.step_id)
        
    except TimeoutError as e:
        # 超时错误
        error_msg = f"步骤执行超时: {step.step_description}"
        logger.error(error_msg)
        raise ExecutionError(error_msg, step_id=step.step_id)
        
    except Exception as e:
        # 未预期的错误
        error_msg = f"步骤执行发生未知错误: {str(e)}"
        logger.exception(error_msg)  # 记录完整堆栈
        raise ExecutionError(error_msg, step_id=step.step_id)
```

## 🔄 开发流程

### 1. Git工作流

#### 分支管理

```bash
# 主分支
main          # 生产版本
develop       # 开发版本

# 功能分支
feature/task-planner-improvement
feature/web-ui-enhancement
feature/new-tool-integration

# 修复分支
bugfix/execution-error-handling
hotfix/critical-security-fix

# 发布分支
release/v1.2.0
```

#### 提交规范

```bash
# 提交消息格式
<type>(<scope>): <subject>

<body>

<footer>

# 类型说明
feat:     新功能
fix:      bug修复
docs:     文档更新
style:    代码格式化
refactor: 重构
test:     测试相关
chore:    构建工具、依赖更新

# 示例
feat(task-planner): 添加任务改进检测功能

实现了对用户输入的改进请求检测，能够识别对已完成任务的
修改要求，并生成相应的改进计划。

- 新增 _detect_task_improvement 方法
- 新增 _handle_task_improvement 方法
- 更新 analyze_task 主流程

Closes #123
```

### 2. 开发流程

#### 功能开发流程

```bash
# 1. 创建功能分支
git checkout develop
git pull origin develop
git checkout -b feature/new-feature

# 2. 开发和测试
# 编写代码...
python -m pytest tests/
python -m flake8 .
python -m black .

# 3. 提交代码
git add -A
git commit -m "feat: 添加新功能"

# 4. 推送并创建PR
git push origin feature/new-feature
# 在GitHub/GitLab创建Pull Request

# 5. 代码审查通过后合并
git checkout develop
git pull origin develop
git branch -d feature/new-feature
```

#### 发布流程

```bash
# 1. 创建发布分支
git checkout develop
git pull origin develop
git checkout -b release/v1.2.0

# 2. 更新版本号和CHANGELOG
echo "1.2.0" > VERSION
# 更新 CHANGELOG.md

# 3. 最终测试
python -m pytest tests/
python scripts/integration_test.py

# 4. 合并到main
git checkout main
git merge release/v1.2.0
git tag v1.2.0
git push origin main --tags

# 5. 合并回develop
git checkout develop
git merge release/v1.2.0
git push origin develop

# 6. 清理
git branch -d release/v1.2.0
```

### 3. 代码审查规范

#### 审查清单

```markdown
## 功能性检查
- [ ] 代码实现符合需求
- [ ] 边界条件处理正确
- [ ] 错误处理完整
- [ ] 异步代码正确使用await

## 代码质量检查
- [ ] 代码风格符合项目规范
- [ ] 命名清晰易懂
- [ ] 函数职责单一
- [ ] 注释和文档完整

## 性能检查
- [ ] 无性能瓶颈
- [ ] 内存使用合理
- [ ] 数据库查询优化
- [ ] 异步操作高效

## 安全检查
- [ ] 输入验证完整
- [ ] 无SQL注入风险
- [ ] 敏感信息未硬编码
- [ ] 权限检查正确

## 测试检查
- [ ] 单元测试覆盖率 > 80%
- [ ] 集成测试通过
- [ ] 边界条件测试
- [ ] 异常情况测试
```

## 🧪 测试规范

### 1. 单元测试

#### 测试结构

```python
# tests/test_task_planner.py
import pytest
from unittest.mock import Mock, AsyncMock, patch
from core.task_planner import TaskPlanner, TaskClarityAnalyzer
from core.models import TaskPlan, TaskClarityScore

class TestTaskPlanner:
    """任务规划器测试类"""
    
    @pytest.fixture
    async def task_planner(self):
        """创建测试用的任务规划器"""
        mock_llm_client = Mock()
        mock_tool_manager = Mock()
        mock_tool_manager.get_tools_for_planning.return_value = []
        
        planner = TaskPlanner(
            llm_client=mock_llm_client,
            tool_manager=mock_tool_manager
        )
        return planner
    
    @pytest.mark.asyncio
    async def test_analyze_simple_task(self, task_planner):
        """测试简单任务分析"""
        # 准备测试数据
        user_input = "生成一个Python hello world程序"
        
        # Mock LLM响应
        mock_response = Mock()
        mock_response.choices[0].message.parsed = TaskClarityScore(
            clarity_score=9,
            has_clear_action=True,
            has_sufficient_params=True,
            is_simple_task=True,
            needs_clarification=False
        )
        
        with patch.object(task_planner.llm_client.beta.chat.completions, 'parse', 
                         return_value=mock_response):
            # 执行测试
            result = await task_planner.analyze_task(user_input)
            
            # 验证结果
            assert isinstance(result, TaskPlan)
            assert result.user_input == user_input
            assert result.task_type != ""
            assert len(result.plan.steps) > 0
    
    @pytest.mark.asyncio
    async def test_analyze_unclear_task_requires_clarification(self, task_planner):
        """测试不明确任务需要澄清"""
        user_input = "帮我生成一个程序"
        
        # Mock返回需要澄清的响应
        mock_clarity_response = Mock()
        mock_clarity_response.choices[0].message.parsed = TaskClarityScore(
            clarity_score=3,
            has_clear_action=False,
            has_sufficient_params=False,
            is_simple_task=False,
            needs_clarification=True
        )
        
        mock_clarification_response = {
            "needs_clarification": True,
            "questions": ["您希望生成什么类型的程序？", "程序需要实现什么功能？"]
        }
        
        with patch.object(task_planner.clarity_analyzer, 'analyze_clarity',
                         return_value=mock_clarity_response.choices[0].message.parsed):
            with patch.object(task_planner, '_analyze_requirements',
                             return_value=mock_clarification_response):
                
                result = await task_planner.analyze_task(user_input)
                
                assert result.requires_clarification == True
                assert len(result.clarification_questions) > 0
                assert "程序" in result.clarification_questions[0]
```

#### 测试覆盖率

```bash
# 运行测试并生成覆盖率报告
python -m pytest tests/ --cov=core --cov-report=html --cov-report=term

# 检查覆盖率阈值
python -m pytest tests/ --cov=core --cov-fail-under=80
```

### 2. 集成测试

```python
# tests/test_integration.py
import pytest
import asyncio
from pathlib import Path
from core import TaskPlanner, TaskExecutor, FileManager
from tools.tool_manager import ToolManager
from communication.mcp_client import MultiMCPClient

class TestSystemIntegration:
    """系统集成测试"""
    
    @pytest.fixture(scope="session")
    async def system_components(self):
        """设置完整系统组件"""
        # 初始化所有组件
        mcp_client = MultiMCPClient()
        tool_manager = ToolManager(mcp_client)
        await tool_manager.load_all_tools()
        
        file_manager = FileManager()
        task_planner = TaskPlanner(
            llm_client=get_test_llm_client(),
            tool_manager=tool_manager
        )
        task_executor = TaskExecutor(
            tool_manager=tool_manager,
            file_manager=file_manager
        )
        
        return {
            'task_planner': task_planner,
            'task_executor': task_executor,
            'file_manager': file_manager,
            'tool_manager': tool_manager
        }
    
    @pytest.mark.asyncio
    async def test_complete_task_workflow(self, system_components):
        """测试完整任务工作流"""
        planner = system_components['task_planner']
        executor = system_components['task_executor']
        
        # 1. 任务分析
        user_input = "生成一个简单的Python计算器"
        task_plan = await planner.analyze_task(user_input)
        
        assert task_plan is not None
        assert not task_plan.requires_clarification
        assert len(task_plan.plan.steps) > 0
        
        # 2. 任务执行
        execution_result = await executor.execute_plan(task_plan)
        
        assert execution_result.success == True
        assert len(execution_result.files_generated) > 0
        
        # 3. 验证生成的文件
        for file_path in execution_result.files_generated:
            assert Path(file_path).exists()
            assert Path(file_path).stat().st_size > 0
```

### 3. 测试数据管理

```python
# tests/fixtures.py
import pytest
from pathlib import Path
import tempfile
import shutil

@pytest.fixture
def temp_test_dir():
    """创建临时测试目录"""
    temp_dir = tempfile.mkdtemp()
    yield Path(temp_dir)
    shutil.rmtree(temp_dir)

@pytest.fixture
def sample_task_plan():
    """创建示例任务计划"""
    from core.models import TaskPlan, Plan, Step
    
    return TaskPlan(
        user_input="测试任务",
        task_type="测试",
        complexity_level="simple",
        plan=Plan(steps=[
            Step(
                step_description="测试步骤",
                function_name="test_tool",
                args={"param": "value"},
                is_final=True
            )
        ])
    )

# 测试配置文件
# pytest.ini
[tool:pytest]
testpaths = tests
python_files = test_*.py
python_classes = Test*
python_functions = test_*
addopts = 
    --strict-markers
    --strict-config
    --cov=core
    --cov=tools
    --cov=communication
    --cov-report=term-missing
    --cov-report=html:htmlcov
    --cov-fail-under=80

markers =
    slow: marks tests as slow
    integration: marks tests as integration tests
    unit: marks tests as unit tests
```

## ⚡ 性能优化

### 1. 异步并发优化

#### 并发执行优化

```python
import asyncio
from concurrent.futures import ThreadPoolExecutor
from typing import List, Any

class OptimizedTaskExecutor:
    """优化的任务执行器"""
    
    def __init__(self, max_concurrent_tools: int = 5):
        self.max_concurrent_tools = max_concurrent_tools
        self.semaphore = asyncio.Semaphore(max_concurrent_tools)
        self.thread_pool = ThreadPoolExecutor(max_workers=4)
    
    async def execute_tools_concurrently(self, tool_calls: List[Dict]) -> List[Any]:
        """并发执行多个工具调用"""
        async def execute_single_tool(tool_call):
            async with self.semaphore:  # 限制并发数
                return await self.tool_manager.call_tool(
                    tool_call['name'], 
                    tool_call['args']
                )
        
        # 创建并发任务
        tasks = [execute_single_tool(call) for call in tool_calls]
        
        # 并发执行
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        return results
    
    async def execute_cpu_intensive_task(self, func, *args, **kwargs):
        """在线程池中执行CPU密集型任务"""
        loop = asyncio.get_event_loop()
        return await loop.run_in_executor(self.thread_pool, func, *args, **kwargs)
```

#### 缓存优化

```python
import asyncio
from functools import lru_cache, wraps
from typing import Dict, Any
import hashlib
import json
import time

class AsyncLRUCache:
    """异步LRU缓存"""
    
    def __init__(self, maxsize: int = 128, ttl: int = 3600):
        self.maxsize = maxsize
        self.ttl = ttl
        self.cache: Dict[str, Dict] = {}
    
    def _get_cache_key(self, func_name: str, args: tuple, kwargs: dict) -> str:
        """生成缓存键"""
        key_data = {
            'func': func_name,
            'args': args,
            'kwargs': kwargs
        }
        key_str = json.dumps(key_data, sort_keys=True, default=str)
        return hashlib.md5(key_str.encode()).hexdigest()
    
    def _is_expired(self, cache_entry: Dict) -> bool:
        """检查缓存是否过期"""
        return time.time() - cache_entry['timestamp'] > self.ttl
    
    def cached(self, func):
        """缓存装饰器"""
        @wraps(func)
        async def wrapper(*args, **kwargs):
            cache_key = self._get_cache_key(func.__name__, args, kwargs)
            
            # 检查缓存
            if cache_key in self.cache:
                cache_entry = self.cache[cache_key]
                if not self._is_expired(cache_entry):
                    return cache_entry['result']
                else:
                    del self.cache[cache_key]
            
            # 执行函数
            result = await func(*args, **kwargs)
            
            # 存储到缓存
            if len(self.cache) >= self.maxsize:
                # 删除最旧的条目
                oldest_key = min(self.cache.keys(), 
                               key=lambda k: self.cache[k]['timestamp'])
                del self.cache[oldest_key]
            
            self.cache[cache_key] = {
                'result': result,
                'timestamp': time.time()
            }
            
            return result
        return wrapper

# 使用示例
cache = AsyncLRUCache(maxsize=100, ttl=1800)

class CachedTaskPlanner(TaskPlanner):
    @cache.cached
    async def analyze_task(self, user_input: str) -> TaskPlan:
        """带缓存的任务分析"""
        return await super().analyze_task(user_input)
```

### 2. 内存优化

#### 内存监控

```python
import psutil
import gc
from typing import Optional
import logging

class MemoryMonitor:
    """内存监控器"""
    
    def __init__(self, max_memory_mb: int = 1024):
        self.max_memory_mb = max_memory_mb
        self.logger = logging.getLogger(__name__)
    
    def get_memory_usage(self) -> Dict[str, float]:
        """获取内存使用情况"""
        process = psutil.Process()
        memory_info = process.memory_info()
        
        return {
            'rss_mb': memory_info.rss / 1024 / 1024,
            'vms_mb': memory_info.vms / 1024 / 1024,
            'percent': process.memory_percent()
        }
    
    def check_memory_limit(self) -> bool:
        """检查内存限制"""
        memory_usage = self.get_memory_usage()
        
        if memory_usage['rss_mb'] > self.max_memory_mb:
            self.logger.warning(f"内存使用超限: {memory_usage['rss_mb']:.1f}MB")
            return False
        
        return True
    
    def force_garbage_collection(self):
        """强制垃圾回收"""
        before = self.get_memory_usage()
        
        gc.collect()
        
        after = self.get_memory_usage()
        freed = before['rss_mb'] - after['rss_mb']
        
        self.logger.info(f"垃圾回收释放内存: {freed:.1f}MB")

# 内存管理装饰器
def memory_managed(max_memory_mb: int = 1024):
    """内存管理装饰器"""
    monitor = MemoryMonitor(max_memory_mb)
    
    def decorator(func):
        @wraps(func)
        async def wrapper(*args, **kwargs):
            # 执行前检查内存
            if not monitor.check_memory_limit():
                monitor.force_garbage_collection()
            
            try:
                result = await func(*args, **kwargs)
                return result
            finally:
                # 执行后清理
                if not monitor.check_memory_limit():
                    monitor.force_garbage_collection()
        
        return wrapper
    return decorator
```

#### 大文件处理优化

```python
import aiofiles
from typing import AsyncIterator

class OptimizedFileManager(FileManager):
    """优化的文件管理器"""
    
    async def read_large_file_chunks(self, 
                                   file_path: str, 
                                   chunk_size: int = 8192) -> AsyncIterator[bytes]:
        """分块读取大文件"""
        async with aiofiles.open(file_path, 'rb') as f:
            while True:
                chunk = await f.read(chunk_size)
                if not chunk:
                    break
                yield chunk
    
    async def process_large_file(self, file_path: str) -> None:
        """处理大文件而不加载到内存"""
        total_size = 0
        hash_obj = hashlib.sha256()
        
        async for chunk in self.read_large_file_chunks(file_path):
            total_size += len(chunk)
            hash_obj.update(chunk)
            
            # 定期检查内存使用
            if total_size % (1024 * 1024) == 0:  # 每1MB检查一次
                gc.collect()
        
        file_hash = hash_obj.hexdigest()
        logger.info(f"文件处理完成: {file_path}, 大小: {total_size}, 哈希: {file_hash}")
```

### 3. 数据库优化

```python
import asyncpg
from typing import List, Dict, Any
import json

class OptimizedDatabase:
    """优化的数据库操作类"""
    
    def __init__(self, connection_pool):
        self.pool = connection_pool
    
    async def batch_insert_tasks(self, tasks: List[Dict[str, Any]]) -> None:
        """批量插入任务"""
        async with self.pool.acquire() as conn:
            # 使用COPY进行批量插入
            await conn.copy_records_to_table(
                'tasks',
                records=[(
                    task['task_id'],
                    task['user_input'],
                    task['task_type'],
                    json.dumps(task['plan']),
                    task['status']
                ) for task in tasks]
            )
    
    async def get_tasks_with_pagination(self, 
                                      user_id: str, 
                                      page: int = 1, 
                                      page_size: int = 20) -> List[Dict]:
        """分页获取任务"""
        offset = (page - 1) * page_size
        
        async with self.pool.acquire() as conn:
            # 使用索引优化查询
            rows = await conn.fetch("""
                SELECT task_id, user_input, task_type, status, created_at
                FROM tasks 
                WHERE user_id = $1 
                ORDER BY created_at DESC 
                LIMIT $2 OFFSET $3
            """, user_id, page_size, offset)
            
            return [dict(row) for row in rows]
```

## 🔒 安全规范

### 1. 输入验证

```python
from pydantic import BaseModel, validator, Field
import re
from typing import Optional

class SecureTaskInput(BaseModel):
    """安全的任务输入模型"""
    
    user_input: str = Field(..., min_length=1, max_length=10000)
    user_id: str = Field(..., regex=r'^[a-zA-Z0-9_-]+$')
    
    @validator('user_input')
    def validate_user_input(cls, v):
        """验证用户输入"""
        # 检查恶意内容
        malicious_patterns = [
            r'<script.*?</script>',  # XSS
            r'javascript:',           # JavaScript协议
            r'on\w+\s*=',            # 事件处理器
            r'eval\s*\(',            # eval函数
            r'exec\s*\(',            # exec函数
        ]
        
        for pattern in malicious_patterns:
            if re.search(pattern, v, re.IGNORECASE):
                raise ValueError(f"输入包含不安全内容")
        
        return v
    
    @validator('user_id')
    def validate_user_id(cls, v):
        """验证用户ID"""
        if len(v) < 3 or len(v) > 50:
            raise ValueError("用户ID长度必须在3-50字符之间")
        return v

# 使用示例
def validate_input(user_input: str, user_id: str) -> SecureTaskInput:
    """验证输入数据"""
    try:
        return SecureTaskInput(user_input=user_input, user_id=user_id)
    except ValidationError as e:
        logger.error(f"输入验证失败: {e}")
        raise
```

### 2. 权限控制

```python
from functools import wraps
from typing import Set, Dict
import jwt
from datetime import datetime, timedelta

class PermissionManager:
    """权限管理器"""
    
    def __init__(self, secret_key: str):
        self.secret_key = secret_key
        self.user_permissions: Dict[str, Set[str]] = {}
    
    def generate_token(self, user_id: str, permissions: Set[str]) -> str:
        """生成访问令牌"""
        payload = {
            'user_id': user_id,
            'permissions': list(permissions),
            'exp': datetime.utcnow() + timedelta(hours=24),
            'iat': datetime.utcnow()
        }
        return jwt.encode(payload, self.secret_key, algorithm='HS256')
    
    def verify_token(self, token: str) -> Dict[str, Any]:
        """验证访问令牌"""
        try:
            payload = jwt.decode(token, self.secret_key, algorithms=['HS256'])
            return payload
        except jwt.ExpiredSignatureError:
            raise PermissionError("令牌已过期")
        except jwt.InvalidTokenError:
            raise PermissionError("无效令牌")
    
    def check_permission(self, user_id: str, required_permission: str) -> bool:
        """检查用户权限"""
        user_perms = self.user_permissions.get(user_id, set())
        return required_permission in user_perms or 'admin' in user_perms

def require_permission(permission: str):
    """权限检查装饰器"""
    def decorator(func):
        @wraps(func)
        async def wrapper(*args, **kwargs):
            # 从请求中获取用户信息
            user_id = kwargs.get('user_id')
            if not user_id:
                raise PermissionError("缺少用户ID")
            
            # 检查权限
            if not permission_manager.check_permission(user_id, permission):
                raise PermissionError(f"用户 {user_id} 缺少权限: {permission}")
            
            return await func(*args, **kwargs)
        return wrapper
    return decorator

# 使用示例
@require_permission('execute_task')
async def execute_task_with_permission(task_plan: TaskPlan, user_id: str):
    """需要权限的任务执行"""
    return await task_executor.execute_plan(task_plan, user_id)
```

### 3. 敏感信息保护

```python
import os
from cryptography.fernet import Fernet
from typing import Optional
import base64

class SecretManager:
    """敏感信息管理器"""
    
    def __init__(self, key: Optional[bytes] = None):
        if key is None:
            # 从环境变量读取密钥
            key_str = os.getenv('ENCRYPTION_KEY')
            if key_str:
                self.key = base64.urlsafe_b64decode(key_str)
            else:
                # 生成新密钥
                self.key = Fernet.generate_key()
        else:
            self.key = key
        
        self.cipher = Fernet(self.key)
    
    def encrypt(self, data: str) -> str:
        """加密敏感数据"""
        encrypted = self.cipher.encrypt(data.encode())
        return base64.urlsafe_b64encode(encrypted).decode()
    
    def decrypt(self, encrypted_data: str) -> str:
        """解密敏感数据"""
        encrypted_bytes = base64.urlsafe_b64decode(encrypted_data.encode())
        decrypted = self.cipher.decrypt(encrypted_bytes)
        return decrypted.decode()

# 配置管理
class SecureConfig:
    """安全配置管理"""
    
    def __init__(self):
        self.secret_manager = SecretManager()
    
    def get_api_key(self, service: str) -> str:
        """获取API密钥"""
        encrypted_key = os.getenv(f'{service.upper()}_API_KEY_ENCRYPTED')
        if encrypted_key:
            return self.secret_manager.decrypt(encrypted_key)
        
        # 如果没有加密版本，检查环境变量
        return os.getenv(f'{service.upper()}_API_KEY', '')
    
    def set_api_key(self, service: str, api_key: str) -> None:
        """设置API密钥"""
        encrypted_key = self.secret_manager.encrypt(api_key)
        os.environ[f'{service.upper()}_API_KEY_ENCRYPTED'] = encrypted_key

# 使用示例
config = SecureConfig()
openai_api_key = config.get_api_key('openai')
```

### 4. 日志安全

```python
import logging
import re
from typing import Any, Dict

class SecureFormatter(logging.Formatter):
    """安全日志格式化器"""
    
    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
        
        # 敏感信息模式
        self.sensitive_patterns = [
            (r'api[_-]?key["\']?\s*[:=]\s*["\']?([a-zA-Z0-9\-_]+)', r'api_key=***'),
            (r'password["\']?\s*[:=]\s*["\']?([^"\'\s]+)', r'password=***'),
            (r'token["\']?\s*[:=]\s*["\']?([a-zA-Z0-9\-_\.]+)', r'token=***'),
            (r'Bearer\s+([a-zA-Z0-9\-_\.]+)', r'Bearer ***'),
        ]
    
    def format(self, record: logging.LogRecord) -> str:
        """格式化日志记录，隐藏敏感信息"""
        # 获取原始消息
        message = super().format(record)
        
        # 替换敏感信息
        for pattern, replacement in self.sensitive_patterns:
            message = re.sub(pattern, replacement, message, flags=re.IGNORECASE)
        
        return message

# 配置安全日志
def setup_secure_logging():
    """设置安全日志配置"""
    logger = logging.getLogger()
    handler = logging.StreamHandler()
    handler.setFormatter(SecureFormatter(
        '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
    ))
    logger.addHandler(handler)
    logger.setLevel(logging.INFO)
```

通过遵循这些开发规范和优化指南，可以确保数字员工系统的代码质量、性能和安全性达到企业级标准。 